import atexit
import logging
import os
import platform
import socket
import sys
import time
from typing import Union

import requests
from celery.signals import worker_init  # type: ignore
from flask_login import user_loaded_from_request, user_logged_in  # type: ignore
from prometheus_client import REGISTRY

from configs import dify_config
from dify_app import DifyApp


@user_logged_in.connect
@user_loaded_from_request.connect
def on_user_loaded(_sender, user):
    if dify_config.ENABLE_OTEL:
        from opentelemetry.trace import get_current_span

        if user:
            current_span = get_current_span()
            if current_span:
                current_span.set_attribute("service.tenant.id", user.current_tenant_id)
                current_span.set_attribute("service.user.id", user.id)


def init_app(app: DifyApp):

    def is_celery_worker():
        return "celery" in sys.argv[0].lower()
    print("ğŸ§¾ å½“å‰è¿›ç¨‹å‘½ä»¤:", sys.argv)
    print("ğŸ§¾ æ˜¯å¦æ˜¯ Celery Worker:", is_celery_worker())

    def instrument_exception_logging():
        exception_handler = ExceptionLoggingHandler()
        logging.getLogger().addHandler(exception_handler)

    def init_flask_instrumentor(app: DifyApp):
        print("ğŸ”§ åˆå§‹åŒ– FlaskInstrumentor")  # æ·»åŠ è°ƒè¯•è¾“å‡º

        meter = get_meter("http_metrics", version=dify_config.CURRENT_VERSION)
        _http_response_counter = meter.create_counter(
            "http.server.response.count", description="Total number of HTTP responses by status code", unit="{response}"
        )
        # æ·»åŠ è¯·æ±‚æŒç»­æ—¶é—´ç›´æ–¹å›¾
        _http_duration_histogram = meter.create_histogram(
            "http.server.duration",
            description="HTTP request duration in milliseconds",
            unit="ms"
        )

        # æ·»åŠ æ´»è·ƒè¯·æ±‚æ•°é‡çš„ä¸Šä¸‹æ–‡ä»ªè¡¨
        _http_active_requests = meter.create_up_down_counter(
            "http.server.active_requests",
            description="Number of active HTTP requests"
        )
        def response_hook(span: Span, status: str, response_headers: list):
            if span and span.is_recording():
                start_time = getattr(span, '_start_time', time.time_ns())
                duration = (time.time_ns() - start_time) / 1_000_000  # è½¬æ¢ä¸ºæ¯«ç§’

                if status.startswith("2"):
                    span.set_status(StatusCode.OK)
                else:
                    span.set_status(StatusCode.ERROR, status)

                status = status.split(" ")[0]
                status_code = int(status)
                status_class = f"{status_code // 100}xx"
                _http_response_counter.add(1, {"status_code": status_code, "status_class": status_class})

                _http_duration_histogram.record(duration, {"status_code": status_code})

        # åœ¨è¯·æ±‚å¼€å§‹æ—¶å¢åŠ æ´»è·ƒè¯·æ±‚æ•°é‡
        def before_request():
            _http_active_requests.add(1)

        # åœ¨è¯·æ±‚ç»“æŸæ—¶å‡å°‘æ´»è·ƒè¯·æ±‚æ•°é‡
        def after_request(response):
            _http_active_requests.add(-1)
            return response

        app.before_request(before_request)
        app.after_request(after_request)

        instrumentor = FlaskInstrumentor()
        if dify_config.DEBUG:
            logging.info("Initializing Flask instrumentor")
        instrumentor.instrument_app(app, response_hook=response_hook)

    def init_sqlalchemy_instrumentor(app: DifyApp):
        with app.app_context():
            engines = list(app.extensions["sqlalchemy"].engines.values())
            SQLAlchemyInstrumentor().instrument(enable_commenter=True, engines=engines)

    def setup_context_propagation():
        # Configure propagators
        set_global_textmap(
            CompositePropagator(
                [
                    TraceContextTextMapPropagator(),  # W3C trace context
                    B3Format(),  # B3 propagation (used by many systems)
                ]
            )
        )

    def shutdown_tracer():
        provider = trace.get_tracer_provider()
        if hasattr(provider, "force_flush"):
            provider.force_flush()

    class ExceptionLoggingHandler(logging.Handler):
        """Custom logging handler that creates spans for logging.exception() calls"""

        def emit(self, record):
            try:
                if record.exc_info:
                    tracer = get_tracer_provider().get_tracer("dify.exception.logging")
                    with tracer.start_as_current_span(
                        "log.exception",
                        attributes={
                            "log.level": record.levelname,
                            "log.message": record.getMessage(),
                            "log.logger": record.name,
                            "log.file.path": record.pathname,
                            "log.file.line": record.lineno,
                        },
                    ) as span:
                        span.set_status(StatusCode.ERROR)
                        span.record_exception(record.exc_info[1])
                        span.set_attribute("exception.type", record.exc_info[0].__name__)
                        span.set_attribute("exception.message", str(record.exc_info[1]))
            except Exception:
                pass

    from opentelemetry import trace
    from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
    from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
    from opentelemetry.instrumentation.celery import CeleryInstrumentor
    from opentelemetry.instrumentation.flask import FlaskInstrumentor
    from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor
    from opentelemetry.metrics import get_meter, get_meter_provider, set_meter_provider
    from opentelemetry.propagate import set_global_textmap
    from opentelemetry.propagators.b3 import B3Format
    from opentelemetry.propagators.composite import CompositePropagator
    from opentelemetry.sdk.metrics import MeterProvider
    from opentelemetry.sdk.metrics.export import ConsoleMetricExporter, PeriodicExportingMetricReader
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import (
        BatchSpanProcessor,
        ConsoleSpanExporter,
    )
    from opentelemetry.sdk.trace.sampling import ParentBasedTraceIdRatio
    from opentelemetry.semconv.resource import ResourceAttributes
    from opentelemetry.trace import Span, get_tracer_provider, set_tracer_provider
    from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
    from opentelemetry.trace.status import StatusCode

    setup_context_propagation()
    # Initialize OpenTelemetry
    # Follow Semantic Convertions 1.32.0 to define resource attributes
    resource = Resource(
        attributes={
            ResourceAttributes.SERVICE_NAME: dify_config.APPLICATION_NAME,
            ResourceAttributes.SERVICE_VERSION: f"dify-{dify_config.CURRENT_VERSION}-{dify_config.COMMIT_SHA}",
            ResourceAttributes.PROCESS_PID: os.getpid(),
            ResourceAttributes.DEPLOYMENT_ENVIRONMENT: f"{dify_config.DEPLOY_ENV}-{dify_config.EDITION}",
            ResourceAttributes.HOST_NAME: socket.gethostname(),
            ResourceAttributes.HOST_ARCH: platform.machine(),
            "custom.deployment.git_commit": dify_config.COMMIT_SHA,
            ResourceAttributes.HOST_ID: platform.node(),
            ResourceAttributes.OS_TYPE: platform.system().lower(),
            ResourceAttributes.OS_DESCRIPTION: platform.platform(),
            ResourceAttributes.OS_VERSION: platform.version(),
        }
    )
    sampler = ParentBasedTraceIdRatio(dify_config.OTEL_SAMPLING_RATE)
    provider = TracerProvider(resource=resource, sampler=sampler)
    set_tracer_provider(provider)
    exporter: Union[OTLPSpanExporter, ConsoleSpanExporter]
    metric_exporter: Union[OTLPMetricExporter, ConsoleMetricExporter]
    #if dify_config.OTEL_EXPORTER_TYPE == "otlp":

    if dify_config.OTEL_EXPORTER_TYPE == "prometheus":
        from opentelemetry.exporter.prometheus import PrometheusMetricReader
        from prometheus_client import start_http_server
        # ç¡®ä¿æŒ‡æ ‡è¢«æ³¨å†Œåˆ° Prometheus å…¨å±€ registry
        def find_available_port(start_port=9464, end_port=9500):
            for port in range(start_port, end_port + 1):
                try:
                    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                        s.bind(("localhost", port))
                    return port
                except OSError:
                    continue
            return 0  # å¦‚æœæ‰¾ä¸åˆ°å¯ç”¨ç«¯å£ï¼Œä½¿ç”¨éšæœºç«¯å£

        port = find_available_port()
        if port == 0:
            print("âš ï¸ æœªæ‰¾åˆ°9464-9500èŒƒå›´å†…çš„å¯ç”¨ç«¯å£ï¼Œä½¿ç”¨éšæœºç«¯å£")

        # å¯åŠ¨æœåŠ¡å™¨å¹¶è·å–æœåŠ¡å™¨å¯¹è±¡
        server_info = start_http_server(port)
        http_server = server_info[0]  # è·å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼šHTTPServer å®ä¾‹
        actual_port = http_server.server_port

        print(f"PrometheusæœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç«¯å£: {actual_port}")
        # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›æµ‹è¯•è„šæœ¬ä½¿ç”¨
        os.environ['PROMETHEUS_METRICS_PORT'] = str(actual_port)

        # ç«‹å³æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦åœ¨ç›‘å¬
        def check_port_listening():
            """æ£€æŸ¥ç«¯å£æ˜¯å¦çœŸæ­£åœ¨ç›‘å¬"""
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.settimeout(1)
                    s.connect(('localhost', actual_port))
                print(f"âœ… ç«¯å£ {actual_port} æ­£åœ¨ç›‘å¬")
                return True
            except Exception as e:
                print(f"âŒ ç«¯å£ {actual_port} æœªåœ¨ç›‘å¬: {str(e)}")
                return False

        # æ‰§è¡Œç«¯å£æ£€æŸ¥
        if not check_port_listening():
            print("âš ï¸ æœåŠ¡å™¨å¯èƒ½æœªæ­£ç¡®å¯åŠ¨")
        # å…ˆè®¾ç½® MeterProvider å†åˆ›å»º PrometheusMetricReader
        reader = PrometheusMetricReader()
        set_meter_provider(MeterProvider(resource=resource, metric_readers=[reader]))

        # éªŒè¯æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
        def check_server():
            time.sleep(1)
            try:
                response = requests.get(f"http://localhost:{actual_port}/metrics", timeout=1)
                print(f"æœåŠ¡å™¨éªŒè¯: {'âœ… æˆåŠŸ' if response.status_code == 200 else f'âŒ çŠ¶æ€ç  {response.status_code}'}")
            except Exception as e:
                print(f"æœåŠ¡å™¨éªŒè¯å¤±è´¥: {str(e)}")
        #reader = PrometheusMetricReader()
        import threading
        threading.Thread(target=check_server).start()

        # è®¾ç½®è·Ÿè¸ªå¯¼å‡ºå™¨
        exporter = OTLPSpanExporter(
            endpoint=dify_config.OTLP_BASE_ENDPOINT + "/v1/traces",
            headers={"Authorization": f"Bearer {dify_config.OTLP_API_KEY}"},
        )

        # ä¸éœ€è¦ metric_exporterï¼Œå› ä¸ºæŒ‡æ ‡ç”± PrometheusMetricReader å¤„ç†
        metric_exporter = None
        '''exporter = OTLPSpanExporter(
            endpoint=dify_config.OTLP_BASE_ENDPOINT + "/v1/traces",
            headers={"Authorization": f"Bearer {dify_config.OTLP_API_KEY}"},
        )
        metric_exporter = OTLPMetricExporter(
            endpoint=dify_config.OTLP_BASE_ENDPOINT + "/v1/metrics",
            headers={"Authorization": f"Bearer {dify_config.OTLP_API_KEY}"},
        )'''
    else:
        # Fallback to console exporter
        exporter = ConsoleSpanExporter()
        metric_exporter = ConsoleMetricExporter()

    provider.add_span_processor(
        BatchSpanProcessor(
            exporter,
            max_queue_size=dify_config.OTEL_MAX_QUEUE_SIZE,
            schedule_delay_millis=dify_config.OTEL_BATCH_EXPORT_SCHEDULE_DELAY,
            max_export_batch_size=dify_config.OTEL_MAX_EXPORT_BATCH_SIZE,
            export_timeout_millis=dify_config.OTEL_BATCH_EXPORT_TIMEOUT,
        )
    )
    if dify_config.OTEL_EXPORTER_TYPE != "prometheus":
        reader = PeriodicExportingMetricReader(
            metric_exporter,
            export_interval_millis=dify_config.OTEL_METRIC_EXPORT_INTERVAL,
            export_timeout_millis=dify_config.OTEL_METRIC_EXPORT_TIMEOUT,
        )
        set_meter_provider(MeterProvider(resource=resource, metric_readers=[reader]))
    else:
    # Prometheus åˆ†æ”¯ä¸­å·²ç»è®¾ç½®äº† MeterProvider
        pass

    def init_custom_metrics():
        meter = get_meter("dify.business", version=dify_config.CURRENT_VERSION)

        # ç”¨æˆ·æ“ä½œè®¡æ•°å™¨
        _user_operations_counter = meter.create_counter(
            "dify.user.operations",
            description="Count of user operations"
        )

        # æ¨¡å‹è°ƒç”¨è®¡æ•°å™¨
        _model_calls_counter = meter.create_counter(
            "dify.model.calls",
            description="Count of model API calls"
        )

        # æ¨¡å‹è°ƒç”¨å»¶è¿Ÿç›´æ–¹å›¾
        _model_latency_histogram = meter.create_histogram(
            "dify.model.latency",
            description="Model API call latency in milliseconds",
            unit="ms"
        )

        # å­˜å‚¨ç”¨é‡ä»ªè¡¨
        _storage_usage_gauge = meter.create_observable_gauge(
            "dify.storage.usage",
            description="Current storage usage in bytes",
            callbacks=[get_storage_usage]
        )

        # å°†æŒ‡æ ‡å­˜å‚¨åœ¨å…¨å±€å˜é‡ä¸­ï¼Œä»¥ä¾¿åœ¨åº”ç”¨ä¸­ä½¿ç”¨
        app.extensions['metrics'] = {
            'user_operations': _user_operations_counter,
            'model_calls': _model_calls_counter,
            'model_latency': _model_latency_histogram
        }

    def get_storage_usage(callback_options):
        # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„å­˜å‚¨ç”¨é‡è·å–é€»è¾‘
        # ä½œä¸ºç¤ºä¾‹è¿”å›0
        yield {
            "value": 0,
            "attributes": {"storage_type": "database"}
        }
    if not is_celery_worker():
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– FlaskInstrumentor")  # æ·»åŠ è°ƒè¯•è¾“å‡º
        meter = get_meter("http_metrics", version=dify_config.CURRENT_VERSION)
        init_flask_instrumentor(app)
        init_custom_metrics()
        CeleryInstrumentor(tracer_provider=get_tracer_provider(), meter_provider=get_meter_provider()).instrument()
    instrument_exception_logging()
    init_sqlalchemy_instrumentor(app)
    atexit.register(shutdown_tracer)


def is_enabled():
    return dify_config.ENABLE_OTEL


@worker_init.connect(weak=False)
def init_celery_worker(*args, **kwargs):
    if dify_config.ENABLE_OTEL:
        from opentelemetry.instrumentation.celery import CeleryInstrumentor
        from opentelemetry.metrics import get_meter_provider
        from opentelemetry.trace import get_tracer_provider

        tracer_provider = get_tracer_provider()
        metric_provider = get_meter_provider()
        if dify_config.DEBUG:
            logging.info("Initializing OpenTelemetry for Celery worker")
        CeleryInstrumentor(tracer_provider=tracer_provider, meter_provider=metric_provider).instrument()
